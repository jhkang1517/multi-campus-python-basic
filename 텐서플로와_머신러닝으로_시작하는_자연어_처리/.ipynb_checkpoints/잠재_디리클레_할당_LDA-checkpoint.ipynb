{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 잠재 디리클레 할당 모델 \n",
    "알파와 베파는 상수\n",
    "단어들로부터 확률을 추출 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA의 가정\n",
    "1. **단어 교환성(exchangeability):** 단어 교환성은 순서를 고려하지 않고, 빈도 수만을 사용한다.  \n",
    "    이를 기반으로, 단어들의 교환성을 구한다.\n",
    "    \n",
    "### LDA할당 절차\n",
    "1. 토픽 개수를 k개로 설정. D개의 전체 문서에, k개의 토픽이 분포되어 있다고 가정\n",
    "2. 모든 단어를 k개 토픽 중 하나에 임의 할당  \n",
    "    그 결과, 각 문서는 토픽을 가지고, 토픽은 단어 분포를 가지게 된다. \n",
    "3. 재할당을 반복\n",
    "    2.에서 임의로 할당하였지만, 올바르게 할당되었다고 가정한다.\n",
    "    p: 문서 d의 단어들 중 토픽 t에 해당하는 단어들의 비율\n",
    "    p: 단어 w를 갖고 있는 모든 문서들 중 토픽 t가 할당된 비율\n",
    "    p: p x p에 따라 토픽할당\n",
    "    \n",
    "결국, 문서, 단어, 토픽의 개수는 사용자가 정한다.  \n",
    "그 이후, 지속적인 재할당 작업을 반복하며, 안정화(**변동이 없을 때까지**)가 되도록 한다. \n",
    "\n",
    "### 한계\n",
    "parameter의 개수 설정값에 따라서 너무 달라진다.  \n",
    "어느정도의 수준에서 parameter숫자를 정해야하는지에 대해서 의견이 분분하다..   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 잠재의미분석(LDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_ls = ['Cute kitty',\n",
    "           'Eat rice or cake',\n",
    "           'Kitty and hamster',\n",
    "           'Eat bread',\n",
    "           'Rice, bread and cake',\n",
    "           'Cute hamster eats bread and cake']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 먼저 소문자로 변환 \n",
    "lower_word_ls = []\n",
    "\n",
    "for docs in docs_ls:\n",
    "    docs = [word.lower() for word in docs.split()]\n",
    "    lower_word_ls.extend(docs)\n",
    "\n",
    "# 모든 단어들\n",
    "lower_word_ls.remove('or')\n",
    "lower_word_ls.remove('and')\n",
    "lower_word_ls.remove('and')\n",
    "lower_word_ls.remove('and')\n",
    "\n",
    "# 중복이 제거된 Unique한 단어들\n",
    "unique_word_ls = list(set(lower_word_ls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cute', 'kitty', 'eat', 'rice', 'cake', 'kitty', 'hamster', 'eat', 'bread', 'rice,', 'bread', 'cake', 'cute', 'hamster', 'eats', 'bread', 'cake']\n",
      "['kitty', 'eat', 'rice', 'cute', 'hamster', 'cake', 'rice,', 'eats', 'bread']\n"
     ]
    }
   ],
   "source": [
    "print(lower_word_ls)\n",
    "print(unique_word_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 1, 1, 1, 2, 2]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "k = 2 # 토픽 개수\n",
    "num = 0.001 # 임의의 상수\n",
    "\n",
    "word_count_ls = []\n",
    "for word in lower_word_ls: \n",
    "    rannumber = random.randrange(1,k+1) # 토픽으로 할당 할 것\n",
    "    word_count_ls.append(rannumber)\n",
    "    \n",
    "word_count_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_array = np.array(lower_word_ls)\n",
    "type(word_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_array = np.array(word_count_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cute' 'kitty' 'eat' 'rice' 'cake' 'kitty' 'hamster' 'eat' 'bread'\n",
      " 'rice,' 'bread' 'cake' 'cute' 'hamster' 'eats' 'bread' 'cake'] [2 2 2 2 2 2 1 2 2 2 2 1 1 1 1 2 2]\n"
     ]
    }
   ],
   "source": [
    "print(word_array, count_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix1 = np.matrix([word_array, count_array])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([['cute', 'kitty', 'eat', 'rice', 'cake', 'kitty', 'hamster',\n",
       "         'eat', 'bread', 'rice,', 'bread', 'cake', 'cute', 'hamster',\n",
       "         'eats', 'bread', 'cake'],\n",
       "        ['2', '2', '2', '2', '2', '2', '1', '2', '2', '2', '2', '1', '1',\n",
       "         '1', '1', '2', '2']], dtype='<U11')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.matrix"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(matrix1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cute</td>\n",
       "      <td>kitty</td>\n",
       "      <td>eat</td>\n",
       "      <td>rice</td>\n",
       "      <td>cake</td>\n",
       "      <td>kitty</td>\n",
       "      <td>hamster</td>\n",
       "      <td>eat</td>\n",
       "      <td>bread</td>\n",
       "      <td>rice,</td>\n",
       "      <td>bread</td>\n",
       "      <td>cake</td>\n",
       "      <td>cute</td>\n",
       "      <td>hamster</td>\n",
       "      <td>eats</td>\n",
       "      <td>bread</td>\n",
       "      <td>cake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0      1    2     3     4      5        6    7      8      9      10  \\\n",
       "0  cute  kitty  eat  rice  cake  kitty  hamster  eat  bread  rice,  bread   \n",
       "1     2      2    2     2     2      2        1    2      2      2      2   \n",
       "\n",
       "     11    12       13    14     15    16  \n",
       "0  cake  cute  hamster  eats  bread  cake  \n",
       "1     1     1        1     1      2     2  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(matrix1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_ls = ['Cute kitty',\n",
    "           'Eat rice or cake',\n",
    "           'Kitty and hamster',\n",
    "           'Eat bread',\n",
    "           'Rice, bread and cake',\n",
    "           'Cute hamster eats bread and cake']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LDA :\n",
    "    def __init__(self, doc_ls, topic_num, alpha = 0.1, beta = 0.001):\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.k = topic_num\n",
    "        \n",
    "    def RandomlyAssignTopic(self, doc_ls):\n",
    "        dic = defaultdict(dict)\n",
    "        t2i = defaultdict(lambda : len(t2i))\n",
    "        i2t = defaultdict()\n",
    "        d = 0\n",
    "        w = 0\n",
    "        \n",
    "        wnl = WordNetLemmatizer()\n",
    "        stopword = stropwords.words('english')\n",
    "        stopword.append('.')\n",
    "        \n",
    "        # 임의의 토픽을 할당\n",
    "        for token in [word_tokenize(doc) for doc in docs]:\n",
    "            for token in [wnl.lemmatize(token.lower()) for token in tokens\n",
    "                         if token not in stopword] :\n",
    "                i2t[t2i[token]] = token\n",
    "                dic[(d, t2i[token], w)] = random.randint(0,self,k-1)\n",
    "                w += 1\n",
    "            d += 1\n",
    "            \n",
    "        print(dic)\n",
    "        return dic, t2i, i2t\n",
    "    \n",
    "    def IterateAssignTopic(self) :\n",
    "        pass\n",
    "    \n",
    "    # 토픽별 주요 키워드 출력\n",
    "    def TopicModeling(self) :\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'self' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-71-d38a110045df>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mLDA\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdoc_ls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtopic_num\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mLDA\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRandomlyAssignTopic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdoc_ls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'self' is not defined"
     ]
    }
   ],
   "source": [
    "LDA.__init__(doc_ls, topic_num=2)\n",
    "LDA.RandomlyAssignTopic(doc_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
