{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import re\n",
    "import scrapy\n",
    "from datetime import timedelta, date\n",
    "from urllib import parse\n",
    "import time\n",
    "import random\n",
    "from time import sleep\n",
    "\n",
    "start_date = date(2018, 1, 1)\n",
    "end_date = date(2019, 6, 20)\n",
    "cnt_per_page = 10\n",
    "keyword = \"마라탕\"\n",
    "\n",
    "url_format = \"https://search.naver.com/search.naver?date_from={0}&date_option=8&date_to={0}&dup_remove=1&nso=so%3Add%2Cp%3Afrom{0}to{0}&post_blogurl=&post_blogurl_without=&query={1}&sm=tab_pge&srchby=all&st=date&where=post&start={2}\"\n",
    "\n",
    "class NaverblogSpider(scrapy.Spider):\n",
    "    def daterange(start_date, end_date):\n",
    "        for n in range(int ((end_date - start_date).days)):\n",
    "            yield start_date + timedelta(n)\n",
    "\n",
    "    name = 'naverblog'\n",
    "    allowed_domains = ['naver.com'] \n",
    "    start_urls = []\n",
    "    \n",
    "    for single_date in daterange(start_date, end_date):\n",
    "        start_urls.append(url_format.format(single_date.strftime(\"%Y%m%d\"), keyword, 1))\n",
    "\n",
    "    def parse(self, response):\n",
    "        for href in response.xpath(\"//ul[@class='type01']/li/dl/dt/a/@href\").extract() :\n",
    "            yield response.follow(href, self.parse_iframe)\n",
    "        \n",
    "        total_cnt = int(re.sub('[()전체건,]', '', response.xpath(\"//div[@class='section_head']/span/text()\").get().split('/')[1]))\n",
    "        query_str = parse.parse_qs(parse.urlsplit(response.url).query)\n",
    "        currpage = int(query_str['start'][0]) \n",
    "\n",
    "        startdate = query_str['date_from'][0]\n",
    "        print(\"=================== [\" + startdate + '] ' + str(currpage) + '/' + str(total_cnt) + \"===================\") \n",
    "        if currpage  < total_cnt : \n",
    "            yield response.follow(url_format.format(startdate, keyword, currpage+10)   , self.parse)\n",
    "\n",
    "    def parse_iframe(self, response):    \n",
    "        href = 'https://blog.naver.com' + response.xpath(\"//iframe/@src\").get()\n",
    "        yield response.follow(href, self.parse_details)\n",
    "\n",
    "    def parse_details(self, response):    \n",
    "        item = NewscrawlItem()\n",
    "        item['url'] = response.url\n",
    "        query_str = parse.parse_qs(parse.urlsplit(response.url).query)\n",
    "        item['author'] = query_str['blogId'][0]\n",
    "\n",
    "        \n",
    "        titlecontent = \"\"\n",
    "        title = \"\"\n",
    "\n",
    "        if 'blog.naver.com' in response.url :\n",
    "            title = str(response.xpath(\"//div[@class='se-module se-module-text se-title-text']/p/span/text()\").get())\n",
    "            item['date'] = response.xpath(\"//span[contains(@class, 'se_publishDate')]/text()\").get()\n",
    "            content = str(response.xpath(\"//div[@class='se-main-container']\").get())\n",
    "\n",
    "            if content == 'None' :\n",
    "                title = str(response.xpath(\"//div[contains(@class,'se_title')]//h3\").get())\n",
    "                item['date'] = response.xpath(\"//span[contains(@class, 'se_publishDate')]/text()\").get()\n",
    "                content = str(response.xpath(\"//div[contains(@class, 'sect_dsc')]\").get())\n",
    "\n",
    "            if content == 'None' :\n",
    "                title = str(response.xpath(\"//div[@class='htitle']/span/text()\").get())\n",
    "                item['date'] = response.xpath(\"//p[contains(@class,'_postAddDate')]/text()\").get()\n",
    "                content = str(response.xpath(\"//div[@id='postViewArea']/div\").get())\n",
    "\n",
    "        title = re.sub(' +', ' ', str(re.sub(re.compile('<.*?>'), ' ', title.replace('\"','')).replace('\\r\\n','').replace('\\n','').replace('\\t','').replace('\\u200b','').strip()))\n",
    "        content = re.sub(' +', ' ', str(re.sub(re.compile('<.*?>'), ' ', content.replace('\"','')).replace('\\r\\n','').replace('\\n','').replace('\\t','').replace('\\u200b','').strip()))\n",
    "        item['title'] = title \n",
    "        item['content'] = content  \n",
    "\n",
    "        yield item"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
