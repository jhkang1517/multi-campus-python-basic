{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM\n",
    "RNN은 hidden layer의 수가 많아질수록, 이전의 데이터를 계속 고려하기 때문에, 데이터가 길어질 수록 전의 가중치가 좀 더 우선되는 경향이 존재한다.\n",
    "  \n",
    "이를 해결 하기 위해 앞 정보를 어느정도(비율)을 유지할 것인지를 고려할 수 있는 모델인 LSTM을 사용한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU (Gated Recurrent Unit)\n",
    "LSTM은 \n",
    "\n",
    "cell state = 장기 정보를 담고 있는 축 \n",
    "rnn에서는 히든 스테이트만 있지만, jyper tans는 -1~1사이로 나오는데,\n",
    "이 과정이 길어질수록 w 가 커지거나 작아질 수 있는데,\n",
    "이를 막기 위해서 sigmoid 값을 넣어서 이를 조절한다. \n",
    "\n",
    "GRU에서는 이러한 cell state를 사용하지 않고,\n",
    "hyper tans를 활용하여 정보의 정도를 조절하기 때문에 cell state를 사용하지 않고도 이를 유지할 수 있다. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN은 시계열을 고려하지 못함\n",
    "RNN은 시계열 가능 그러나 자기 문맥에 대한 정보를 고려하지 못함\n",
    "때문에 LSTM과 GRU가 나옴\n",
    "\n",
    "그러니 이러한 것으로도 장기의 문맥(즉 번역이나 학습을 할떄)을 제대로 고려하지 못함.\n",
    "특히 초기의 문맥이 잘 담기지 못함 \n",
    "그러면 어디에 집중해야 더 이러한 것을 잘할까? \n",
    "\n",
    "에서 나온게\n",
    "\n",
    "Seq2Seq with Attention \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lab-12-6 sequence to sequence with attention (Keras + eager version)\n",
    "\n",
    "### simple neural machine translation training\n",
    "\n",
    "* sequence to sequence\n",
    "  \n",
    "### Reference\n",
    "* [Sequence to Sequence Learning with Neural Networks](https://arxiv.org/abs/1409.3215)\n",
    "* [Effective Approaches to Attention-based Neural Machine Translation](https://arxiv.org/abs/1508.04025)\n",
    "* [Neural Machine Translation with Attention from Tensorflow](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/eager/python/examples/nmt_with_attention/nmt_with_attention.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "# Import TensorFlow >= 1.10 and enable eager execution\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "from matplotlib import font_manager, rc\n",
    "\n",
    "rc('font', family='AppleGothic') #for mac\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = [['I', 'feel', 'hungry'],\n",
    "     ['tensorflow', 'is', 'very', 'difficult'],\n",
    "     ['tensorflow', 'is', 'a', 'framework', 'for', 'deep', 'learning'],\n",
    "     ['tensorflow', 'is', 'very', 'fast', 'changing']]\n",
    "targets = [['나는', '배가', '고프다'],\n",
    "           ['텐서플로우는', '매우', '어렵다'],\n",
    "           ['텐서플로우는', '딥러닝을', '위한', '프레임워크이다'],\n",
    "           ['텐서플로우는', '매우', '빠르게', '변화한다']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<pad>': 0,\n",
      " 'I': 1,\n",
      " 'a': 2,\n",
      " 'changing': 3,\n",
      " 'deep': 4,\n",
      " 'difficult': 5,\n",
      " 'fast': 6,\n",
      " 'feel': 7,\n",
      " 'for': 8,\n",
      " 'framework': 9,\n",
      " 'hungry': 10,\n",
      " 'is': 11,\n",
      " 'learning': 12,\n",
      " 'tensorflow': 13,\n",
      " 'very': 14}\n"
     ]
    }
   ],
   "source": [
    "# vocabulary for sources\n",
    "s_vocab = list(set(sum(sources, [])))\n",
    "s_vocab.sort()\n",
    "s_vocab = ['<pad>'] + s_vocab\n",
    "source2idx = {word : idx for idx, word in enumerate(s_vocab)}\n",
    "idx2source = {idx : word for idx, word in enumerate(s_vocab)}\n",
    "\n",
    "pprint(source2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<bos>': 1,\n",
      " '<eos>': 2,\n",
      " '<pad>': 0,\n",
      " '고프다': 3,\n",
      " '나는': 4,\n",
      " '딥러닝을': 5,\n",
      " '매우': 6,\n",
      " '배가': 7,\n",
      " '변화한다': 8,\n",
      " '빠르게': 9,\n",
      " '어렵다': 10,\n",
      " '위한': 11,\n",
      " '텐서플로우는': 12,\n",
      " '프레임워크이다': 13}\n"
     ]
    }
   ],
   "source": [
    "# vocabulary for targets\n",
    "t_vocab = list(set(sum(targets, [])))\n",
    "t_vocab.sort()\n",
    "t_vocab = ['<pad>', '<bos>', '<eos>'] + t_vocab\n",
    "target2idx = {word : idx for idx, word in enumerate(t_vocab)}\n",
    "idx2target = {idx : word for idx, word in enumerate(t_vocab)}\n",
    "\n",
    "pprint(target2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(sequences, max_len, dic, mode = 'source'):\n",
    "    assert mode in ['source', 'target'], 'source와 target 중에 선택해주세요.'\n",
    "    \n",
    "    if mode == 'source':\n",
    "        # preprocessing for source (encoder)\n",
    "        s_input = list(map(lambda sentence : [dic.get(token) for token in sentence], sequences))\n",
    "        s_len = list(map(lambda sentence : len(sentence), s_input))\n",
    "        s_input = pad_sequences(sequences = s_input, maxlen = max_len, padding = 'post', truncating = 'post')\n",
    "        return s_len, s_input\n",
    "    \n",
    "    elif mode == 'target':\n",
    "        # preprocessing for target (decoder)\n",
    "        # input\n",
    "        t_input = list(map(lambda sentence : ['<bos>'] + sentence + ['<eos>'], sequences))\n",
    "        t_input = list(map(lambda sentence : [dic.get(token) for token in sentence], t_input))\n",
    "        t_len = list(map(lambda sentence : len(sentence), t_input))\n",
    "        t_input = pad_sequences(sequences = t_input, maxlen = max_len, padding = 'post', truncating = 'post')\n",
    "        \n",
    "        # output\n",
    "        t_output = list(map(lambda sentence : sentence + ['<eos>'], sequences))\n",
    "        t_output = list(map(lambda sentence : [dic.get(token) for token in sentence], t_output))\n",
    "        t_output = pad_sequences(sequences = t_output, maxlen = max_len, padding = 'post', truncating = 'post')\n",
    "        \n",
    "        return t_len, t_input, t_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 4, 7, 5] [[ 1  7 10  0  0  0  0  0  0  0]\n",
      " [13 11 14  5  0  0  0  0  0  0]\n",
      " [13 11  2  9  8  4 12  0  0  0]\n",
      " [13 11 14  6  3  0  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "# preprocessing for source\n",
    "s_max_len = 10\n",
    "s_len, s_input = preprocess(sequences = sources,\n",
    "                            max_len = s_max_len, dic = source2idx, mode = 'source')\n",
    "print(s_len, s_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 5, 6, 6] [[ 1  4  7  3  2  0  0  0  0  0  0  0]\n",
      " [ 1 12  6 10  2  0  0  0  0  0  0  0]\n",
      " [ 1 12  5 11 13  2  0  0  0  0  0  0]\n",
      " [ 1 12  6  9  8  2  0  0  0  0  0  0]] [[ 4  7  3  2  0  0  0  0  0  0  0  0]\n",
      " [12  6 10  2  0  0  0  0  0  0  0  0]\n",
      " [12  5 11 13  2  0  0  0  0  0  0  0]\n",
      " [12  6  9  8  2  0  0  0  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "# preprocessing for target\n",
    "t_max_len = 12\n",
    "t_len, t_input, t_output = preprocess(sequences = targets,\n",
    "                                      max_len = t_max_len, dic = target2idx, mode = 'target')\n",
    "print(t_len, t_input, t_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hyper-param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper-parameters\n",
    "epochs = 100\n",
    "batch_size = 4\n",
    "learning_rate = .005\n",
    "total_step = epochs / batch_size\n",
    "buffer_size = 100\n",
    "n_batch = buffer_size//batch_size\n",
    "embedding_dim = 32\n",
    "units = 128\n",
    "\n",
    "# input\n",
    "data = tf.data.Dataset.from_tensor_slices((s_len, s_input, t_len, t_input, t_output))\n",
    "data = data.shuffle(buffer_size = buffer_size)\n",
    "data = data.batch(batch_size = batch_size)\n",
    "# s_mb_len, s_mb_input, t_mb_len, t_mb_input, t_mb_output = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gru(units):\n",
    "  # If you have a GPU, we recommend using CuDNNGRU(provides a 3x speedup than GRU)\n",
    "  # the code automatically does that.\n",
    "    if tf.test.is_gpu_available():\n",
    "        return tf.keras.layers.CuDNNGRU(units, \n",
    "                                        return_sequences=True, \n",
    "                                        return_state=True, \n",
    "                                        recurrent_initializer='glorot_uniform')\n",
    "    else:\n",
    "        return tf.keras.layers.GRU(units, \n",
    "                                   return_sequences=True, \n",
    "                                   return_state=True, \n",
    "                                   recurrent_activation='sigmoid', \n",
    "                                   recurrent_initializer='glorot_uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.enc_units = enc_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = gru(self.enc_units)\n",
    "        \n",
    "    def call(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        output, state = self.gru(x, initial_state = hidden)\n",
    "#         print(\"state: {}\".format(state.shape))\n",
    "#         print(\"output: {}\".format(state.shape))\n",
    "              \n",
    "        return output, state\n",
    "    \n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_sz, self.enc_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = gru(self.dec_units)\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "        \n",
    "        # used for attention\n",
    "        self.W1 = tf.keras.layers.Dense(self.dec_units)\n",
    "        self.W2 = tf.keras.layers.Dense(self.dec_units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "        \n",
    "    def call(self, x, hidden, enc_output):\n",
    "        # enc_output shape == (batch_size, max_length, hidden_size)\n",
    "        \n",
    "        # hidden shape == (batch_size, hidden size)\n",
    "        # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
    "        # we are doing this to perform addition to calculate the score\n",
    "        hidden_with_time_axis = tf.expand_dims(hidden, 1)\n",
    "        # * `score = FC(tanh(FC(EO) + FC(H)))`\n",
    "        # score shape == (batch_size, max_length, 1)\n",
    "        # we get 1 at the last axis because we are applying tanh(FC(EO) + FC(H)) to self.V\n",
    "        score = self.V(tf.nn.tanh(self.W1(enc_output) + self.W2(hidden_with_time_axis)))\n",
    "                \n",
    "        #* `attention weights = softmax(score, axis = 1)`. Softmax by default is applied on the last axis but here we want to apply it on the *1st axis*, since the shape of score is *(batch_size, max_length, 1)*. `Max_length` is the length of our input. Since we are trying to assign a weight to each input, softmax should be applied on that axis.\n",
    "        # attention_weights shape == (batch_size, max_length, 1)\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "        \n",
    "        # context_vector shape after sum == (batch_size, hidden_size)\n",
    "        # * `context vector = sum(attention weights * EO, axis = 1)`. Same reason as above for choosing axis as 1.\n",
    "        context_vector = attention_weights * enc_output\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "        \n",
    "        # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
    "        # * `embedding output` = The input to the decoder X is passed through an embedding layer.\n",
    "        x = self.embedding(x)\n",
    "        \n",
    "        # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
    "        # * `merged vector = concat(embedding output, context vector)`\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "        \n",
    "        # passing the concatenated vector to the GRU\n",
    "        output, state = self.gru(x)\n",
    "        \n",
    "        # output shape == (batch_size * 1, hidden_size)\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "        \n",
    "        # output shape == (batch_size * 1, vocab)\n",
    "        x = self.fc(output)\n",
    "        \n",
    "        return x, state, attention_weights\n",
    "        \n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_sz, self.dec_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(len(source2idx), embedding_dim, units, batch_size)\n",
    "decoder = Decoder(len(target2idx), embedding_dim, units, batch_size)\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = 1 - np.equal(real, 0)\n",
    "    loss_ = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=real, logits=pred) * mask\n",
    "    \n",
    "#     print(\"real: {}\".format(real))\n",
    "#     print(\"pred: {}\".format(pred))\n",
    "#     print(\"mask: {}\".format(mask))\n",
    "#     print(\"loss: {}\".format(tf.reduce_mean(loss_)))\n",
    "    \n",
    "    return tf.reduce_mean(loss_)\n",
    "\n",
    "# creating optimizer\n",
    "optimizer = tf.train.AdamOptimizer()\n",
    "\n",
    "# creating check point (Object-based saving)\n",
    "checkpoint_dir = './data_out/training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, 'ckpt')\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                encoder=encoder,\n",
    "                                decoder=decoder)\n",
    "\n",
    "# create writer for tensorboard\n",
    "summary_writer = tf.contrib.summary.create_file_writer(logdir=checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss 0.0396 Batch Loss 0.9896\n",
      "Epoch 10 Loss 0.0380 Batch Loss 0.9505\n",
      "Epoch 20 Loss 0.0346 Batch Loss 0.8649\n",
      "Epoch 30 Loss 0.0327 Batch Loss 0.8171\n",
      "Epoch 40 Loss 0.0302 Batch Loss 0.7561\n",
      "Epoch 50 Loss 0.0258 Batch Loss 0.6442\n",
      "Epoch 60 Loss 0.0177 Batch Loss 0.4435\n",
      "Epoch 70 Loss 0.0113 Batch Loss 0.2815\n",
      "Epoch 80 Loss 0.0068 Batch Loss 0.1689\n",
      "Epoch 90 Loss 0.0034 Batch Loss 0.0856\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 100\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    \n",
    "    hidden = encoder.initialize_hidden_state()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for i, (s_len, s_input, t_len, t_input, t_output) in enumerate(data):\n",
    "        loss = 0\n",
    "        with tf.GradientTape() as tape:\n",
    "            enc_output, enc_hidden = encoder(s_input, hidden)\n",
    "            \n",
    "            dec_hidden = enc_hidden\n",
    "            \n",
    "            dec_input = tf.expand_dims([target2idx['<bos>']] * batch_size, 1)\n",
    "            \n",
    "            #Teacher Forcing: feeding the target as the next input\n",
    "            for t in range(1, t_input.shape[1]):\n",
    "                predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
    "                \n",
    "                loss += loss_function(t_input[:, t], predictions)\n",
    "            \n",
    "                dec_input = tf.expand_dims(t_input[:, t], 1) #using teacher forcing\n",
    "                \n",
    "        batch_loss = (loss / int(t_input.shape[1]))\n",
    "        \n",
    "        total_loss += batch_loss\n",
    "        \n",
    "        variables = encoder.variables + decoder.variables\n",
    "        \n",
    "        gradient = tape.gradient(loss, variables)\n",
    "        \n",
    "        optimizer.apply_gradients(zip(gradient, variables))\n",
    "        \n",
    "    if epoch % 10 == 0:\n",
    "        #save model every 10 epoch\n",
    "        print('Epoch {} Loss {:.4f} Batch Loss {:.4f}'.format(epoch,\n",
    "                                            total_loss / n_batch,\n",
    "                                            batch_loss.numpy()))\n",
    "        checkpoint.save(file_prefix = checkpoint_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(sentence, encoder, decoder, inp_lang, targ_lang, max_length_inp, max_length_targ):\n",
    "    attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
    "    \n",
    "#     sentence = preprocess_sentence(sentence)\n",
    "\n",
    "    inputs = [inp_lang[i] for i in sentence.split(' ')]\n",
    "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs], maxlen=max_length_inp, padding='post')\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "    \n",
    "    result = ''\n",
    "\n",
    "    hidden = [tf.zeros((1, units))]\n",
    "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "\n",
    "    dec_hidden = enc_hidden\n",
    "    dec_input = tf.expand_dims([targ_lang['<bos>']], 0)\n",
    "\n",
    "    for t in range(max_length_targ):\n",
    "        predictions, dec_hidden, attention_weights = decoder(dec_input, dec_hidden, enc_out)\n",
    "        \n",
    "        # storing the attention weigths to plot later on\n",
    "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "        attention_plot[t] = attention_weights.numpy()\n",
    "\n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "\n",
    "        result += idx2target[predicted_id] + ' '\n",
    "\n",
    "        if idx2target.get(predicted_id) == '<eos>':\n",
    "            return result, sentence, attention_plot\n",
    "        \n",
    "        # the predicted ID is fed back into the model\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "    return result, sentence, attention_plot\n",
    "\n",
    "# result, sentence, attention_plot = evaluate(sentence, encoder, decoder, source2idx, target2idx,\n",
    "#                                             s_max_len, t_max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for plotting the attention weights\n",
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(attention, cmap='viridis')\n",
    "    \n",
    "    fontdict = {'fontsize': 14}\n",
    "    \n",
    "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(sentence, encoder, decoder, inp_lang, targ_lang, max_length_inp, max_length_targ):\n",
    "    result, sentence, attention_plot = evaluate(sentence, encoder, decoder, inp_lang, targ_lang, max_length_inp, max_length_targ)\n",
    "        \n",
    "    print('Input: {}'.format(sentence))\n",
    "    print('Predicted translation: {}'.format(result))\n",
    "    \n",
    "    attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
    "    plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x284e273dd68>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#restore checkpoint\n",
    "\n",
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: tensorflow feel hungry\n",
      "Predicted translation: 나는 배가 고프다 <eos> \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sentence = 'I feel hungry'\n",
    "# sentence = 'tensorflow is a framework for deep learning'\n",
    "sentence = 'tensorflow feel hungry'\n",
    "\n",
    "translate(sentence, encoder, decoder, source2idx, target2idx, s_max_len, t_max_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
