{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://www.wildml.com/2016/08/rnns-in-tensorflow-a-practical-guide-and-undocumented-features/\n",
    "# http://learningtensorflow.com/index.html\n",
    "# http://suriyadeepan.github.io/2016-12-31-practical-seq2seq/\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.contrib import rnn\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding for each char in 'hello'\n",
    "h = [1, 0, 0, 0]\n",
    "e = [0, 1, 0, 0]\n",
    "l = [0, 0, 1, 0]\n",
    "o = [0, 0, 0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope('one_cell') as scope:\n",
    "    # One cell RNN input_dim (4) -> output_dim (2)\n",
    "    hidden_size = 2\n",
    "    cell = tf.keras.layers.SimpleRNNCell(units=hidden_size) # keras = tf를 더 쉽게 사용! \n",
    "    print(cell.output_size, cell.state_size)\n",
    "\n",
    "    x_data = np.array([[h]], dtype=np.float32) # x_data = [[[1,0,0,0]]]\n",
    "    pp.pprint(x_data)\n",
    "    outputs, _states = tf.nn.dynamic_rnn(cell, x_data, dtype=tf.float32)\n",
    "\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    pp.pprint(outputs.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope('two_sequances') as scope:\n",
    "    # One cell RNN input_dim (4) -> output_dim (2). sequence: 5\n",
    "    hidden_size = 2\n",
    "    cell = tf.keras.layers.SimpleRNNCell(units=hidden_size)\n",
    "    x_data = np.array([[h, e, l, l, o]], dtype=np.float32) # 앞에서 선언한 변수 h, e, l, o  \n",
    "    print(x_data.shape)\n",
    "    pp.pprint(x_data)\n",
    "    outputs, _states = tf.nn.dynamic_rnn(cell, x_data, dtype=tf.float32)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    pp.pprint(outputs.eval())\n",
    "    \n",
    "# array안에 있는 값의 큰 의미는 없고, vector 화 되었다는 의미정도로 해석 할 것 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope('3_batches') as scope:\n",
    "    # One cell RNN input_dim (4) -> output_dim (2). sequence: 5, batch 3\n",
    "    # 3 batches 'hello', 'eolll', 'lleel'\n",
    "    x_data = np.array([[h, e, l, l, o],\n",
    "                       [e, o, l, l, l],\n",
    "                       [l, l, e, e, l]], dtype=np.float32)\n",
    "    pp.pprint(x_data)\n",
    "    \n",
    "    hidden_size = 2\n",
    "    cell = tf.nn.rnn_cell.LSTMCell(num_units=hidden_size, state_is_tuple=True)\n",
    "    outputs, _states = tf.nn.dynamic_rnn(\n",
    "        cell, x_data, dtype=tf.float32)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    pp.pprint(outputs.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### h,e,l,o RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lab 12 RNN\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "tf.set_random_seed(777)  # reproducibility\n",
    "\n",
    "idx2char = ['h', 'i', 'e', 'l', 'o']\n",
    "# Teach hello: hihell -> ihello\n",
    "x_data = [[0, 1, 0, 2, 3, 3]]   # hihell\n",
    "x_one_hot = [[[1, 0, 0, 0, 0],   # h 0\n",
    "              [0, 1, 0, 0, 0],   # i 1\n",
    "              [1, 0, 0, 0, 0],   # h 0\n",
    "              [0, 0, 1, 0, 0],   # e 2\n",
    "              [0, 0, 0, 1, 0],   # l 3\n",
    "              [0, 0, 0, 1, 0]]]  # l 3\n",
    "\n",
    "y_data = [[1, 0, 2, 3, 3, 4]]    # ihello\n",
    "\n",
    "num_classes = 5\n",
    "input_dim = 5  # one-hot size\n",
    "hidden_size = 5  # output from the LSTM. 5 to directly predict one-hot\n",
    "batch_size = 1   # one sentence\n",
    "sequence_length = 6  # |ihello| == 6\n",
    "learning_rate = 0.1\n",
    "\n",
    "X = tf.placeholder(\n",
    "    tf.float32, [None, sequence_length, input_dim])  # X one-hot\n",
    "Y = tf.placeholder(tf.int32, [None, sequence_length])  # Y label\n",
    "\n",
    "cell = tf.contrib.rnn.BasicLSTMCell(num_units=hidden_size, state_is_tuple=True)\n",
    "initial_state = cell.zero_state(batch_size, tf.float32)\n",
    "outputs, _states = tf.nn.dynamic_rnn(\n",
    "    cell, X, initial_state=initial_state, dtype=tf.float32)\n",
    "\n",
    "# FC layer\n",
    "X_for_fc = tf.reshape(outputs, [-1, hidden_size])\n",
    "# fc_w = tf.get_variable(\"fc_w\", [hidden_size, num_classes])\n",
    "# fc_b = tf.get_variable(\"fc_b\", [num_classes])\n",
    "# outputs = tf.matmul(X_for_fc, fc_w) + fc_b\n",
    "outputs = tf.contrib.layers.fully_connected(\n",
    "    inputs=X_for_fc, num_outputs=num_classes, activation_fn=None)\n",
    "\n",
    "# reshape out for sequence_loss\n",
    "outputs = tf.reshape(outputs, [batch_size, sequence_length, num_classes])\n",
    "\n",
    "weights = tf.ones([batch_size, sequence_length])\n",
    "sequence_loss = tf.contrib.seq2seq.sequence_loss(\n",
    "    logits=outputs, targets=Y, weights=weights)\n",
    "loss = tf.reduce_mean(sequence_loss)\n",
    "train = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\n",
    "\n",
    "prediction = tf.argmax(outputs, axis=2)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(50):\n",
    "        l, _ = sess.run([loss, train], feed_dict={X: x_one_hot, Y: y_data})\n",
    "        result = sess.run(prediction, feed_dict={X: x_one_hot})\n",
    "        print(i, \"loss:\", l, \"prediction: \", result, \"true Y: \", y_data)\n",
    "\n",
    "        # print char using dic\n",
    "        result_str = [idx2char[c] for c in np.squeeze(result)]\n",
    "        print(\"\\tPrediction str: \", ''.join(result_str))\n",
    "\n",
    "'''\n",
    "0 loss: 1.71584 prediction:  [[2 2 2 3 3 2]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
    "\tPrediction str:  eeelle\n",
    "1 loss: 1.56447 prediction:  [[3 3 3 3 3 3]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
    "\tPrediction str:  llllll\n",
    "2 loss: 1.46284 prediction:  [[3 3 3 3 3 3]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
    "\tPrediction str:  llllll\n",
    "3 loss: 1.38073 prediction:  [[3 3 3 3 3 3]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
    "\tPrediction str:  llllll\n",
    "4 loss: 1.30603 prediction:  [[3 3 3 3 3 3]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
    "\tPrediction str:  llllll\n",
    "5 loss: 1.21498 prediction:  [[3 3 3 3 3 3]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
    "\tPrediction str:  llllll\n",
    "6 loss: 1.1029 prediction:  [[3 0 3 3 3 4]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
    "\tPrediction str:  lhlllo\n",
    "7 loss: 0.982386 prediction:  [[1 0 3 3 3 4]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
    "\tPrediction str:  ihlllo\n",
    "8 loss: 0.871259 prediction:  [[1 0 3 3 3 4]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
    "\tPrediction str:  ihlllo\n",
    "9 loss: 0.774338 prediction:  [[1 0 2 3 3 4]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
    "\tPrediction str:  ihello\n",
    "10 loss: 0.676005 prediction:  [[1 0 2 3 3 4]] true Y:  [[1, 0, 2, 3, 3, 4]]\n",
    "\tPrediction str:  ihello\n",
    "\n",
    "...\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 12-2 many to one stacking\n",
    "sentence sentiment classification\n",
    "\n",
    "* many to one\n",
    "* variable input sequence length\n",
    "* stacking\n",
    "* drop out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Sequential, Model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from pprint import pprint\n",
    "%matplotlib inline\n",
    "\n",
    "print(tf.__version__)\n",
    "tf.enable_eager_execution() # eager_execution( 세션 호출 없이 바로바로 결과값을 확인할 수 있다.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preparing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example data\n",
    "sentences = ['What I cannot create, I do not understand.',\n",
    "             'Intellecuals solve problems, geniuses prevent them',\n",
    "             'A person who never made a mistake never tied anything new.',\n",
    "             'The same equations have the same solutions.']\n",
    "y_data = [1,0,0,1] # 1: richard feynman, 0: albert einstein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a token dictionary\n",
    "char_set = ['<pad>'] + sorted(list(set(''.join(sentences))))\n",
    "idx2char = {idx : char for idx, char in enumerate(char_set)}\n",
    "char2idx = {char : idx for idx, char in enumerate(char_set)}\n",
    "\n",
    "print(char_set)\n",
    "print(idx2char)\n",
    "print(char2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting sequence of tokens to sequence of indices\n",
    "x_data = list(map(lambda sentence : [char2idx.get(char) for char in sentence], sentences))\n",
    "x_data_len = list(map(lambda sentence : len(sentence), sentences))\n",
    "\n",
    "print(x_data)\n",
    "print(x_data_len)\n",
    "print(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# padding the sequence of indices\n",
    "max_sequence = 55\n",
    "x_data = pad_sequences(sequences = x_data, maxlen = max_sequence,\n",
    "                       padding = 'post', truncating = 'post')\n",
    "\n",
    "# checking data\n",
    "print(x_data)\n",
    "print(x_data_len)\n",
    "print(y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating stacked rnn for \"many to one\" classification with dropout\n",
    "num_classes = 2\n",
    "hidden_dims = [10,10]\n",
    "\n",
    "input_dim = len(char2idx)\n",
    "output_dim = len(char2idx)\n",
    "one_hot = np.eye(len(char2idx))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Embedding(input_dim=input_dim, output_dim=output_dim,\n",
    "                           trainable=False, mask_zero=True, input_length=max_sequence,\n",
    "                           embeddings_initializer=keras.initializers.Constant(one_hot)))\n",
    "model.add(layers.SimpleRNN(units=hidden_dims[0], return_sequences=True))\n",
    "model.add(layers.TimeDistributed(layers.Dropout(rate = .2)))\n",
    "model.add(layers.SimpleRNN(units=hidden_dims[1]))\n",
    "model.add(layers.Dropout(rate = .2))\n",
    "model.add(layers.Dense(units=num_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating loss function\n",
    "def loss_fn(model, x, y, training):\n",
    "    return tf.losses.sparse_softmax_cross_entropy(labels=y, logits=model(x, training))\n",
    "\n",
    "# creating and optimizer\n",
    "lr = .01\n",
    "epochs = 30\n",
    "batch_size = 2\n",
    "opt = tf.train.AdamOptimizer(learning_rate = lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating data pipeline\n",
    "tr_dataset = tf.data.Dataset.from_tensor_slices((x_data, y_data))\n",
    "tr_dataset = tr_dataset.shuffle(buffer_size=4)\n",
    "tr_dataset = tr_dataset.batch(batch_size=batch_size)\n",
    "\n",
    "print(tr_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "tr_loss_hist = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    avg_tr_loss = 0\n",
    "    tr_step = 0\n",
    "    \n",
    "    for x_mb, y_mb in tr_dataset:\n",
    "        with tf.GradientTape() as tape:\n",
    "            tr_loss = loss_fn(model, x=x_mb, y=y_mb, training=True)\n",
    "        grads = tape.gradient(target=tr_loss, sources=model.variables)\n",
    "        opt.apply_gradients(grads_and_vars=zip(grads, model.variables))\n",
    "        avg_tr_loss += tr_loss\n",
    "        tr_step += 1\n",
    "    else:\n",
    "        avg_tr_loss /= tr_step\n",
    "        tr_loss_hist.append(avg_tr_loss)\n",
    "    \n",
    "    if (epoch + 1) % 5 ==0:\n",
    "        print('epoch : {:3}, tr_loss : {:.3f}'.format(epoch + 1, avg_tr_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 100.00%\n"
     ]
    }
   ],
   "source": [
    "yhat = model.predict(x_data)\n",
    "yhat = np.argmax(yhat, axis=-1)\n",
    "print('accuracy : {:.2%}'.format(np.mean(yhat == y_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1f467726be0>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(tr_loss_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
