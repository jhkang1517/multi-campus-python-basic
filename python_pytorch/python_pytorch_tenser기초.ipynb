{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.cuda # GPU 지원\n",
    "from torch import Storage # 1차원 배열, single data type 저장소\n",
    "import torch.nn # NN 모듈s --> Parameter, Container, Layer, Utility # nural network. # 가장 중요 모듈\n",
    "import torch.nn.functional # NN functions\n",
    "import torch.nn.init # initialize \n",
    "import torch.optim # 최적화 알고리즘\n",
    "import torch.autograd # Gradient 자동 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.distributed # 분산처리\n",
    "import torch.distributions # 분포\n",
    "\n",
    "import torch.multiprocessing # 멀티프로세싱 모듈 wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils \n",
    "from torch.utils import bottleneck # Bottleneck 디버깅\n",
    "from torch.utils import checkpoint \n",
    "from torch.utils import cpp_extension # cpp3지원\n",
    "from torch.utils import data\n",
    "from torch.utils import dlpack\n",
    "from torch.utils import model_zoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.jit # Torch Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 텐서 (Tensor) 기본\n",
    "torch.Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "pytorch란?\n",
    "tenserflow와 비슷하지만, 파이프 라인을 구축하고 실행시키는 방식이 아닌,\n",
    "단계적으로 파이프 라인을 구축해 나가면서 실행시키는 방식이라는 점이 다르다.\n",
    "Define and run / Define by run \n",
    "\n",
    "1. 인공신경망이란?\\n\n",
    "컴퓨터도 사람의 뉴런처럼 구성한다면 인공지능이 되지 않을까? 라는 발상에서 시작\n",
    "\n",
    "뉴런 = 노드\n",
    "입력신호 = 입력\n",
    "축색돌기 = 가중치\n",
    "시냅스 = 활성화 함수(Activate Function)\n",
    "\n",
    "뉴런의 작동과정을 설명하자면,\n",
    "여러 신호들이 들어오는데, 이 입력신호의 세기가 어떠한 임계치(선)을 넘어가는 순간에만 다른 뉴런에게 전달이 된다.\n",
    "이 전달을 해주는 매개체가 시냅스이며, 이 시냅스가 바로 활성화함수이다. \n",
    "\n",
    "요약.\n",
    "(가중치 x 입력신호)들이 노드에 전달되고, 이 노드에 전달된 신호가 활성화함수를 거쳐 출력되거나 전달된다. \n",
    "활성화 함수는 다른 노드로 정보를 보내는 정도를 보내준다. \n",
    "\n",
    "1-1. 스텝함수\n",
    "활성화 함수로 가장 많이 사용되는 함수가 바로 스텝함수이다. \n",
    "일정신호가 어느정도 수준 이하일때에는 0을 출력하고, 어느정도 수준을 초과하면 1을 출력하게 된다. \n",
    "== 특정한 값 이상일때에는 1을 출력하고, 특정한 값 이하일때는 0을 출력한다. \n",
    "대략적인 느낌을 코드로 본다면 if문과 매우 유사하다. \n",
    "if x > 0:\n",
    "    step(x) = 1\n",
    "if x <= 0:\n",
    "    step(x) = 0\n",
    "    \n",
    "다시, 스텝함수는 입력값이 0 이상이여야 출력값이 1이 되고, 그렇지 않으면 출력값이 0이 된다. \n",
    "즉, 가중치를 조정해 나가면서 목적변수(실제값)과 예측값이 일치하도록 조정해 나가는 학습과정이 필요할 것이다. \n",
    "\n",
    "한계점은, AND OR의 연산으로는 비 선형적인 관계를 나타낼 수 없다는 점이다.\n",
    "그나마 선으로 나눌 수 있는 것은 풀 수 있지만, 곡선의 경우에는 풀 수 없다. \n",
    "이를 위해, 다중 퍼셉트론을 구성한다. 여러개의 퍼셉트론을 조합하여 문제를 하나씩 풀어나간다. \n",
    "\n",
    "순전파와 역전파의 개념 정확하게 이해해야합니다. \n",
    "\n",
    "\n",
    "용어설명\n",
    "tensor: 어떠한 값\n",
    "그 값의 형태는 float형일수도 있고, int형일수도 있다. \n",
    "그 형태는 스칼라가 될 수도 있고, 벡터도 될 수 있고 행렬도 될 수 있는 다차원의 값으로 정의한다. \n",
    "\n",
    "벡터이기 때문에 벡터연산도 가능하고, 행렬연산도 가능하다.\n",
    "그런데, 이 tensor값은 grad라는 값을 가질 수 있다. default는 None이라는 것\n",
    "\n",
    "frontward 순정파\n",
    "backward 역전파\n",
    "\n",
    "grad:\n",
    "결국 tensor는 신경망을 구성하기 위한 하나의 값들로 사용된다. \n",
    "backward 하기 위한 어떠한 기능인데, 이 기능 중에서는 grad function이라는 것이 있고, grad라는 것이 있다. \n",
    "grad라는 것은 무엇인가?\n",
    "grad function의 결과가 바로 grad이다.\n",
    "그런데 이 grad funcion은 여러개가 있다. 단순한 사칙연산뿐만이 아니라 다양한 함수들이 들어갈 수 도 있다.\n",
    "grad가 변하면 결과값에 영향을 미친다. \n",
    "grad function은 grad를 계산하기 위한 함수 \n",
    "grad를 계산하기 위해서는 require_grad를 true로 만들어주어야한다. \n",
    "\n",
    "\n",
    "\n",
    "우리는 신경망을 구성할때 연산을 구성하지는 않는다. 단지 값들만을 \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4.5402e-43,        nan],\n",
       "        [0.0000e+00, 0.0000e+00]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.Tensor(2,2) # = torch.FloatTensor\n",
    "# 2행 2열을 계산한다. 기본적으로 float 형 \n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type:  torch.FloatTensor\n",
      "size:  torch.Size([2, 2])\n",
      "개수:  4\n"
     ]
    }
   ],
   "source": [
    "print('type: ', x.type()) \n",
    "print('size: ', x.size()) # shape와 동일한 기능.\n",
    "# print('size2: ', x.shape())\n",
    "print('개수: ', x.numel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1.2387e-42],\n",
       "          [0.0000e+00]],\n",
       "\n",
       "         [[0.0000e+00],\n",
       "          [0.0000e+00]],\n",
       "\n",
       "         [[0.0000e+00],\n",
       "          [0.0000e+00]]],\n",
       "\n",
       "\n",
       "        [[[0.0000e+00],\n",
       "          [0.0000e+00]],\n",
       "\n",
       "         [[0.0000e+00],\n",
       "          [0.0000e+00]],\n",
       "\n",
       "         [[0.0000e+00],\n",
       "          [0.0000e+00]]],\n",
       "\n",
       "\n",
       "        [[[0.0000e+00],\n",
       "          [0.0000e+00]],\n",
       "\n",
       "         [[0.0000e+00],\n",
       "          [0.0000e+00]],\n",
       "\n",
       "         [[0.0000e+00],\n",
       "          [0.0000e+00]]],\n",
       "\n",
       "\n",
       "        [[[0.0000e+00],\n",
       "          [0.0000e+00]],\n",
       "\n",
       "         [[0.0000e+00],\n",
       "          [0.0000e+00]],\n",
       "\n",
       "         [[0.0000e+00],\n",
       "          [0.0000e+00]]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4차원\n",
    "x2 = torch.Tensor(4,3,2,1)\n",
    "x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type:  torch.FloatTensor\n",
      "size:  torch.Size([4, 3, 2, 1])\n",
      "개수:  24\n"
     ]
    }
   ],
   "source": [
    "print('type: ', x2.type())\n",
    "print('size: ', x2.size())\n",
    "print('개수: ', x2.numel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 텐서를 만드는 또 다른 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "b: tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]])\n",
      "c: tensor([[1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1.]])\n",
      "d: tensor([[0.1621, 0.7160, 0.7478, 0.1989],\n",
      "        [0.6962, 0.9187, 0.4669, 0.2237],\n",
      "        [0.2248, 0.1306, 0.5774, 0.9196],\n",
      "        [0.0030, 0.2826, 0.0385, 0.8033]])\n",
      "e: tensor([[ 0.3356, -0.7975, -0.3934,  0.1966],\n",
      "        [ 0.0184,  0.0736,  1.4094,  1.0902],\n",
      "        [-0.0257,  0.0516,  1.5806, -1.1464],\n",
      "        [ 2.0526,  0.9560, -1.0761,  1.9994]])\n"
     ]
    }
   ],
   "source": [
    "# 영행렬\n",
    "a = torch.zeros(4, 4) # numpy에도 있는 함수들 \n",
    "print('a:', a)\n",
    "\n",
    "# 일행렬\n",
    "b = torch.ones(4,4)\n",
    "print('b:',b)\n",
    "\n",
    "# 단위 행렬\n",
    "c = torch.eye(4,4) \n",
    "print('c:',c)\n",
    "\n",
    "# 0과1사이 난수\n",
    "d = torch.rand(4,4)\n",
    "print('d:',d)\n",
    "\n",
    "# 정규분포 추출 N(0,1)\n",
    "e = torch.randn(4,4) # 정규분포 \n",
    "print('e:',e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.3000, 0.6000, 0.9000, 1.2000, 1.5000, 1.8000, 2.1000, 2.4000,\n",
       "        2.7000])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x3 = torch.arange(0, 3, step=0.3) # np.arange()\n",
    "# numpy처럼 사용할 수 있다. \n",
    "x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6., 2.],\n",
       "        [3., 4.],\n",
       "        [5., 6.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor([[6,2],[3,4],[5,6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5  6]\n",
      " [10 11]]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "numpy_test = np.array([[5,6],[10,11]])\n",
    "print(numpy_test)\n",
    "print(type(numpy_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5,  6],\n",
       "        [10, 11]], dtype=torch.int32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.from_numpy(numpy_test)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5,  6],\n",
       "       [10, 11]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.numpy() # 서로간 호환이 가능하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Tensor Slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  2.,  3.,  4.],\n",
      "        [ 5.,  6.,  7.,  8.],\n",
      "        [ 9., 10., 11., 12.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([[1,2,3,4],[5,6,7,8],[9,10,11,12]])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  2.,  3.,  4.],\n",
       "        [ 5.,  6.,  7.,  8.],\n",
       "        [ 9., 10., 11., 12.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#모든 원소 출력\n",
    "x[:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.,  6.,  7.,  8.],\n",
       "        [ 9., 10., 11., 12.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2행부터 출력\n",
    "x[1:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.,  3.,  4.],\n",
       "        [ 6.,  7.,  8.],\n",
       "        [10., 11., 12.]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2열부터 출력\n",
    "x[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6.,  7.],\n",
       "        [10., 11.]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2행, 2열부터 3열까지 출력\n",
    "x[1:, 1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3., 4.])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1행 출력\n",
    "x[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  2.,  3.,  4.],\n",
       "        [ 5.,  6.,  7.,  8.],\n",
       "        [ 9., 10., 11., 12.]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[1., 2., 3., 4.]]), tensor([[5., 6., 7., 8.]]), tensor([[ 9., 10., 11., 12.]]))\n"
     ]
    }
   ],
   "source": [
    "#x를 1행씩 잘라서 배열의 Tuple로 저장\n",
    "x_rows = torch.split(x, split_size_or_sections=1, dim=0)\n",
    "# split_size_or_sections: n 단위로 잘라낼 것이다. \n",
    "# dimension: 0은 행단위 ,1은 열단위 \n",
    "print(x_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[ 1.,  2.],\n",
      "        [ 5.,  6.],\n",
      "        [ 9., 10.]]), tensor([[ 3.,  4.],\n",
      "        [ 7.,  8.],\n",
      "        [11., 12.]]))\n"
     ]
    }
   ],
   "source": [
    "#x를 2열씩 잘라서 배열의 Tuple로 저장\n",
    "x_cols = torch.split(x, split_size_or_sections=2, dim=1)\n",
    "print(x_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.,  2.],\n",
       "         [ 5.,  6.],\n",
       "         [ 9., 10.]]), tensor([[ 3.,  4.],\n",
       "         [ 7.,  8.],\n",
       "         [11., 12.]]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#위와 같은 결과\n",
    "x_chunk = torch.chunk(x, chunks=2, dim=1)\n",
    "# chunk: 똑같음\n",
    "x_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1],\n",
       "        [1, 0],\n",
       "        [0, 1]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.ByteTensor([[0,1],[1,0],[0,1]])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  2.],\n",
       "        [ 5.,  6.],\n",
       "        [ 9., 10.]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_cols[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2.,  5., 10.])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#x_cols의 첫번째 배열 중 특정 부분만 추출하기\n",
    "torch.masked_select(x_cols[0], torch.ByteTensor([[0,1],[1,0],[0,1]]))\n",
    "# mask: 마스크를 씌운다.\n",
    "# ByteTensor: 0과 1의 사이값을 가진다. \n",
    "# 1번째, 0번째, 1번째를 가져온다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Tensor 합치기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cat: 차원 유지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3., 4.]]),\n",
       " tensor([[5., 6., 7., 8.]]),\n",
       " tensor([[ 9., 10., 11., 12.]]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  2.,  3.,  4.],\n",
       "        [ 5.,  6.,  7.,  8.],\n",
       "        [ 9., 10., 11., 12.]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x_rows를 행으로 이어 붙이기\n",
    "torch.cat(x_rows, dim=0) # dim: axis와 같음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x_rows를 열로 이어 붙이기\n",
    "torch.cat(x_rows, dim=1) # dim: axis와 같음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.,  2.],\n",
       "         [ 5.,  6.],\n",
       "         [ 9., 10.]]), tensor([[ 3.,  4.],\n",
       "         [ 7.,  8.],\n",
       "         [11., 12.]]))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_col1, x_col2 = x_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  2.],\n",
      "        [ 5.,  6.],\n",
      "        [ 9., 10.]])\n",
      "tensor([[ 3.,  4.],\n",
      "        [ 7.,  8.],\n",
      "        [11., 12.]])\n"
     ]
    }
   ],
   "source": [
    "print(x_col1, x_col2, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stack: 차원 확대"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.,  2.],\n",
      "         [ 5.,  6.],\n",
      "         [ 9., 10.]],\n",
      "\n",
      "        [[ 3.,  4.],\n",
      "         [ 7.,  8.],\n",
      "         [11., 12.]]])\n",
      "torch.Size([2, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "# x_cols를 쌓아올리기\n",
    "# 합치는 것이 아니라, 쌓은 개념이므로 차원이 늘어난다. (3차원으로 늘어남)\n",
    "x_new = torch.stack([x_col1, x_col2], dim=0) # dim: axis와 같음 \n",
    "print(x_new)\n",
    "print(x_new.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.,  2.],\n",
      "         [ 3.,  4.]],\n",
      "\n",
      "        [[ 5.,  6.],\n",
      "         [ 7.,  8.]],\n",
      "\n",
      "        [[ 9., 10.],\n",
      "         [11., 12.]]])\n",
      "torch.Size([3, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "#x_cols를 쌓아올리기\n",
    "x_new = torch.stack([x_col1, x_col2], dim=1) # dim: axis와 같음 \n",
    "print(x_new)\n",
    "print(x_new.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 Tensor Reshaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  2.,  3.,  4.],\n",
      "        [ 5.,  6.,  7.,  8.],\n",
      "        [ 9., 10., 11., 12.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([[1,2,3,4],[5,6,7,8],[9,10,11,12]])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  2.,  3.],\n",
       "        [ 4.,  5.,  6.],\n",
       "        [ 7.,  8.,  9.],\n",
       "        [10., 11., 12.]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4행 3열로 바꾸기 # reshpae과 같음\n",
    "x.view(4, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  2.],\n",
       "        [ 3.,  4.],\n",
       "        [ 5.,  6.],\n",
       "        [ 7.,  8.],\n",
       "        [ 9., 10.],\n",
       "        [11., 12.]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2열로 바꾸기\n",
    "# 12개 이므로 6행 2열이 될 것이다.\n",
    "x.view(-1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.,  2.,  3.,  4.,  5.,  6.]],\n",
      "\n",
      "        [[ 7.,  8.,  9., 10., 11., 12.]]])\n",
      "Size: torch.Size([2, 1, 6])\n"
     ]
    }
   ],
   "source": [
    "y = x.view(2, 1, -1)\n",
    "# 왜 2 1 6 인가?\n",
    "print(y)\n",
    "print(\"Size:\", y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.,  2.,  3.,  4.,  5.,  6.]],\n",
      "\n",
      "        [[ 7.,  8.,  9., 10., 11., 12.]]])\n",
      "Size: torch.Size([2, 1, 6])\n"
     ]
    }
   ],
   "source": [
    "y = x.view(2, 1, -1)\n",
    "print(y)\n",
    "print(\"Size:\", y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  2.,  3.,  4.,  5.,  6.],\n",
      "        [ 7.,  8.,  9., 10., 11., 12.]])\n",
      "Size: torch.Size([2, 6])\n"
     ]
    }
   ],
   "source": [
    "#차원이 1인 값을 축소\n",
    "# squeeze: 차원이 1인 것들은 전부 사라지게 된다.\n",
    "y = y.squeeze()\n",
    "print(y)\n",
    "print(\"Size:\", y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.,  2.,  3.,  4.,  5.,  6.]],\n",
      "\n",
      "        [[ 7.,  8.,  9., 10., 11., 12.]]])\n",
      "Size: torch.Size([2, 1, 6])\n"
     ]
    }
   ],
   "source": [
    "# dim= 1 자리에 차원을 추가\n",
    "# 행, 열이 아닌 \"자리\"에 추가하는 것이다. 즉, 0, 1, 2번째 자리중 어디에 추가할 것인가? 라는 의미\n",
    "y = x.view(2, 1, -1).squeeze().unsqueeze(dim=1)\n",
    "print(y)\n",
    "print(\"Size:\", y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.],\n",
      "         [ 2.],\n",
      "         [ 3.],\n",
      "         [ 4.],\n",
      "         [ 5.],\n",
      "         [ 6.]],\n",
      "\n",
      "        [[ 7.],\n",
      "         [ 8.],\n",
      "         [ 9.],\n",
      "         [10.],\n",
      "         [11.],\n",
      "         [12.]]])\n",
      "Size: torch.Size([2, 6, 1])\n"
     ]
    }
   ],
   "source": [
    "#dim=2 자리에 차원을 추가 (차원)\n",
    "y = x.view(2, 1, -1).squeeze().unsqueeze(dim=2)\n",
    "print(y)\n",
    "print(\"Size:\", y.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7 GPU를 위한 Tensor - Cuda\n",
    "CUDA(Computed Unified Device Architecture)  \n",
    "NVIDIA만 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [1., 2., 3.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([[1,2,3],[1,2,3]])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 Cuda 사용 가능한 Device 개수 : 0\n",
      "현재 Cuda 사용 가능 여부 : False\n"
     ]
    }
   ],
   "source": [
    "# cuda 확인\n",
    "# 멀티캠퍼스 컴퓨터로는 사용이 불가능\n",
    "print(\"현재 Cuda 사용 가능한 Device 개수 :\", torch.cuda.device_count())\n",
    "print(\"현재 Cuda 사용 가능 여부 :\", torch.cuda.is_available())\n",
    "# print(\"현재 사용 중인 Cuda Device :\", torch.cuda.current_device())\n",
    "# print(\"현재 Cuda Device 이름 :\", torch.cuda.get_device_name(0))\n",
    "# print(\"현재 Cuda Device의 사용 가능한 메모리 :\", torch.cuda.max_memory_allocated(device=0), \"bytes\")\n",
    "# print(\"현재 Cuda Device의 사용 중인 메모리 :\", torch.cuda.memory_allocated(device=0), \"bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.8 Tensor 연산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x : tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "y : tensor([[1., 1., 1.],\n",
      "        [2., 2., 2.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([[1,2,3],[4,5,6]])\n",
    "y = torch.Tensor([[1,1,1],[2,2,2]])\n",
    "print(\"x :\", x)\n",
    "print(\"y :\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z : tensor([[2., 3., 4.],\n",
      "        [6., 7., 8.]])\n",
      "x+y : tensor([[2., 3., 4.],\n",
      "        [6., 7., 8.]])\n"
     ]
    }
   ],
   "source": [
    "# x와 y의 합\n",
    "z = torch.add(x, y)\n",
    "print(\"z :\", z)\n",
    "print(\"x+y :\", x+y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.,  0.,  1.],\n",
      "        [ 2.,  3.,  4.]])\n",
      "tensor([[ 2.,  4.,  6.],\n",
      "        [ 8., 10., 12.]])\n"
     ]
    }
   ],
   "source": [
    "# x의 모든 원소에서 2를 뺌\n",
    "print(x - 2)\n",
    "\n",
    "# x의 모든 원소에 2를 곱함\n",
    "print(2*x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z : tensor([[ 1.,  2.,  3.],\n",
      "        [ 8., 10., 12.]])\n",
      "x*y : tensor([[ 1.,  2.,  3.],\n",
      "        [ 8., 10., 12.]])\n"
     ]
    }
   ],
   "source": [
    "#x의 원소와 y의 원소를 각각 곱함\n",
    "z = torch.mul(x, y)\n",
    "print(\"z :\", z)\n",
    "print(\"x*y :\", x*y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z : tensor([[ 1.,  4.,  9.],\n",
      "        [16., 25., 36.]])\n",
      "x**2 : tensor([[ 1.,  4.,  9.],\n",
      "        [16., 25., 36.]])\n"
     ]
    }
   ],
   "source": [
    "#x의 원소를 각각 제곱함\n",
    "z = torch.pow(x, 2)\n",
    "print(\"z :\", z)\n",
    "print(\"x**2 :\", x**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z : tensor([[0.0000, 0.6931, 1.0986],\n",
      "        [1.3863, 1.6094, 1.7918]])\n",
      "x.log() : tensor([[0.0000, 0.6931, 1.0986],\n",
      "        [1.3863, 1.6094, 1.7918]])\n"
     ]
    }
   ],
   "source": [
    "#x의 원소에 log를 씌움\n",
    "z = torch.log(x)\n",
    "print(\"z :\", z)\n",
    "print(\"x.log() :\", x.log())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z : tensor([[1.0000, 1.4142, 1.7321],\n",
      "        [2.0000, 2.2361, 2.4495]])\n",
      "x.sqrt() : tensor([[1.0000, 1.4142, 1.7321],\n",
      "        [2.0000, 2.2361, 2.4495]])\n"
     ]
    }
   ],
   "source": [
    "#x의 원소에 루트를 씌움\n",
    "z = torch.sqrt(x)\n",
    "print(\"z :\", z)\n",
    "print(\"x.sqrt() :\", x.sqrt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1.],\n",
      "        [0., 1., 0.]])\n"
     ]
    }
   ],
   "source": [
    "#x의 원소에 나머지(mod) 계산\n",
    "z = x % 2\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z : tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "x.abs() : tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n"
     ]
    }
   ],
   "source": [
    "#x에 절댓값\n",
    "z = torch.abs(x)\n",
    "print(\"z :\", z)\n",
    "print(\"x.abs() :\", x.abs())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.9 Tensor 타입변환(Casting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x : tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "y : tensor([[1., 1., 1.],\n",
      "        [2., 2., 2.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([[1,2,3],[4,5,6]])\n",
    "y = torch.Tensor([[1,1,1],[2,2,2]])\n",
    "print(\"x :\", x)\n",
    "print(\"y :\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 5., 6.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Double: 실수를 표현하지만, float보다 더 넓은 범위를 표현할 수 있다.\n",
    "x.type(torch.DoubleTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 5., 6.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6]], dtype=torch.int32)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.type(torch.IntTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6]], dtype=torch.int32)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.int()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.10 Tensor 통계연산(Statistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.,  2., -3.],\n",
      "        [ 4., -5.,  6.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([[-1,2,-3],[4,-5,6]])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x의 합 : tensor(3.)\n",
      "x의 최대값 : tensor(6.)\n",
      "x의 최소값 : tensor(-5.)\n",
      "x의 분산 : tensor(17.9000)\n"
     ]
    }
   ],
   "source": [
    "print(\"x의 합 :\", x.sum())\n",
    "print(\"x의 최대값 :\", x.max())\n",
    "print(\"x의 최소값 :\", x.min())\n",
    "print(\"x의 분산 :\", x.var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scalar Tensor\n",
    "# scalar는 차원이 없음\n",
    "x.sum().size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x의 합 : 3.0\n",
      "x의 최대값 : 6.0\n",
      "x의 최소값 : -5.0\n",
      "x의 분산 : 17.899999618530273\n"
     ]
    }
   ],
   "source": [
    "# item의 활용\n",
    "print(\"x의 합 :\", x.sum().item())\n",
    "print(\"x의 최대값 :\", x.max().item())\n",
    "print(\"x의 최소값 :\", x.min().item())\n",
    "print(\"x의 분산 :\", x.var().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4., 2., 6.])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 행을 기준으로 열의 최댓값을 출력\n",
    "# dimension의 활용\n",
    "value, index = x.max(dim=0)\n",
    "value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([2., 6.]), tensor([1, 2]))"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#열을 기준으로 행의 최댓값을 출력\n",
    "x.max(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3., -1.,  2.],\n",
       "        [-5.,  4.,  6.]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 열을 기준으로 각 행을 정렬\n",
    "# sort를 사용\n",
    "value, index = x.sort(dim=1)\n",
    "value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.11 Tensor function (*_like ) \n",
    "모양이 같음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.,  2., -3.],\n",
      "        [ 4., -5.,  6.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([[-1,2,-3],[4,-5,6]])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "y = torch.zeros_like(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "y = torch.ones_like(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0594, 0.3936, 0.5026],\n",
      "        [0.5657, 0.1699, 0.9986]])\n"
     ]
    }
   ],
   "source": [
    "y = torch.rand_like(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.12 Tensor 행렬연산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x : tensor([[1., 1.],\n",
      "        [2., 2.]])\n",
      "y : tensor([[1., 2.],\n",
      "        [3., 4.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([[1,1],[2,2]])\n",
    "y = torch.Tensor([[1,2],[3,4]])\n",
    "print(\"x :\", x)\n",
    "print(\"y :\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.,  6.],\n",
       "        [ 8., 12.]])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x와 y의 행렬곱 - multiply matrix\n",
    "torch.mm(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [2., 2.]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 6.])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#x와 z의 행렬벡터곱 - Multiply Vector\n",
    "z = torch.Tensor([1, 2])\n",
    "torch.mv(x, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2.])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# z와 z의 내적\n",
    "# 내적이 뭔데?\n",
    "torch.dot(z, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [1., 2.]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#x의 전치(transpose)\n",
    "x.t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.0000,  1.0000],\n",
       "        [ 1.5000, -0.5000]])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y의 역행렬(inverse)\n",
    "y.inverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
