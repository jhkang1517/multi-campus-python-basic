{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, Linear Regression!!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "들어가며\n",
    "Linear Regerssion == 선형회귀\n",
    "통계학에서, 선형 회귀(線型回歸, 영어: linear regression)는 \n",
    "종속 변수 y와 한 개 이상의 독립 변수 (또는 설명 변수) X와의 선형 상관 관계를 모델링하는 회귀분석 기법이다. \n",
    "한 개의 설명 변수에 기반한 경우에는 단순 선형 회귀, 둘 이상의 설명 변수에 기반한 경우에는 다중 선형 회귀라고 한다.\n",
    "\n",
    "두 변수, 혹은 여러 개의 변수들간 관계를 보여주는 데이터에서 어떠한 패턴을 찾아내고자 하는 것이 연구자들의 목적이다.\n",
    "그 중, 선형 적합(linear fitting)은 가장 많이 사용되는 방법이다. \n",
    "단 하나의 선으로 주어진 데이터의 패턴을 설명할 수 있다는 것은 굉장히 매력적이기 때문이다.\n",
    "\n",
    "우리 모두는 일차함수에 대해서 알고 있다. x축과 y축의 좌표평면 상에 하나의 선으로 나타나는 것이 바로 일차함수이다.\n",
    "선형회귀는 바로 이 일차함수를 이용하는 것이다. 어떠한 독립변수(x)와 종속변수(y)는 좌표평면위에 흩뿌려져 있을 것이고,\n",
    "이와 가장 적합(fit)한 직선을 찾아내는 것은, 다시 말해 최적의 기울기와 절편을 가진 일차함수를 찾아내는 것과 동일하다.\n",
    "\n",
    "그렇다면, 이러한 직선을 어떻게 구할 것인지가 문제로 남는다.\n",
    "다행스럽게도, 선형회귀의 역사는 오래되었고, 많은 수학자들은 이에 대한 해답을 내놓았다.\n",
    "따라서 우리는 어떻게 적절한 직선을 구할 것인지에 대한 원리를 탐구하는 것보다는, \n",
    "이미 해답이 제시되어 있는 여러 수학적 지식들을 이해하는 것이 보다 더 중요할 것이다.\n",
    "\n",
    "그럼에도 불구하고, 잠시 수학적인 얘기가 필수불가결하다.\n",
    "최대한 간단하게 설명해보자면, 실제 데이터(실제값)과 우리가 예측한 어떠한 선(일차함수)에는 분명한 차이가 존재할 것이다.\n",
    "그러한 차이를 우리는 오차(error)라고 한다. 이 오차를 최소화 하는 것이 곧 가장 적절한 일차함수를 찾는 것과 동일하다.\n",
    "\n",
    "그런데 여기서 문제가 발생한다. 좌표평면을 상상해보자. 무작위로 흩뿌려져있는 점들 사이로 직선이 하나 지나간다.\n",
    "여기서, 직선이 점들의 '사이'를 지나간다는 것은 점들이 직선의 '위'와 '아래'에 놓여져 있다는 것을 의미한다.\n",
    "직선보다 위에 있는 점과의 차이는 반드시 양수일 것이고,\n",
    "직선보다 아래에 있는 점과의 차이는 반드시 음수일 것이다.\n",
    "따라서 문제가 발생한다. 오차를 최소화 하기 위해서는 오차들을 전부 더해보아야하는데, \n",
    "오차가 양수와 음수라면 서로 더해지면서 상쇄가 될 것이기 때문이다.\n",
    "\n",
    "이를 어떻게 해결해야할 것인가?\n",
    "답은 간단하다. 오차를 절대값으로 만들어 계산하거나, 오차를 제곱(^2)해주면 된다.\n",
    "이 중, 선형회귀에서 가장 많이 사용되는 방법은 오차제곱의 합을 최소화하는 직선을 찾는 것이다. \n",
    "이 오차제곱의 합을 SSE(Sum of Squared Errors)라고 부른다.\n",
    "그리고 이 오차제곱의 합을 최소화하는 직선을 찾기위한 방법이 바로 최소자승법이다.\n",
    "\n",
    "다시 한번 생각해보자. \n",
    "우리의 목표는 완벽한 일차함수, 최적합(fit)직선을 찾는 것이고, 이를 위해서 오차제곱의 합을 최소화해야하며, 최소자승법을 사용해야 한다. \n",
    "오차는 앞서 말했듯, 실제값과 예측값의 차이이다. 그런데 우리가 만든 예측식은 필연적으로 정확하지 않기 때문에,\n",
    "미지수로 생각해도 무방할 것이다.\n",
    "\n",
    "오차를 미지수로 생각하면, 오차를 제곱하여 최소화가 되도록 만든다는 것은 곧 2차 함수의 최소점을 찾는 것을 의미한다.\n",
    "우리 모두가 알다싶이, 2차함수는 반드시 최소점이 존재한다. \n",
    "이 최소점을 찾는다는 것은, 곧 1차함수의 기울기 값을 알게된다는 말과 동일하다.\n",
    "\n",
    "여기서 많은 사람들이 좌절한다. 2차함수의 최소점을 구하는 것이 어떻게 1차함수의 기울기를 찾게 되는 것인가?\n",
    "이를 이해하기 위해서는 미분과 편미분에 대해서 알아야하지만, 그러한 방식이 아닌 보다 쉬운 방식으로 설명을 해보려고한다.\n",
    "\n",
    "먼저 우리는 방금 오차를 미지수로 두고, 2차함수를 만들었다.\n",
    "알다싶이, 2차함수는 반드시 최소점이 존재하는 함수이다. (제곱을 했기 때문에 반드시 양수이고, U자 모양일 것이다.)\n",
    "여기까지 이해했다면, 우선 이부분만 기억하고 다음 말을 이해해보자.\n",
    "\n",
    "선은 어떻게 만들어지는가? 두 점을 이어서 만들어진다.\n",
    "일차함수를 생각해보자. y 절편(bias)은 어떻게 구하는가? y = ax + b라는 함수에서 x에 0을 넣으면 b가 절편이다.\n",
    "우리의 예측식 역시 일차함수이기 때문에, x에 0을 넣는다면 예측식의 절편은 매우 쉽게 구할 수 있을 것이다.\n",
    "이렇게 점 하나를 구한다.\n",
    "\n",
    "그 다음으로, 아까 기억한 오차의 함수, 즉 2차함수를 보자. 2차 함수 역시 최소점이 존재한다. \n",
    "그렇다면, 그 최소점과 아까구한 절편을 잇는다면? 바로 그 순간 선이 완성된다.\n",
    "이 선은 1차함수일 것이고,\n",
    "이 1차함수가 바로 최적합(best-fitting) 직선(line)이다.\n",
    "이후에는 다들 배웠지만 기억나지 않을 뿐인 중학교 수준의 연립방정식를 거쳐 기울기(a)가 구해진다.\n",
    "\n",
    "이것이 선형회귀의 전부이다. \n",
    "미지의 1차함수 포맷을 만들고, 실제값과의 차이(오차)를 제곱하여 2차함수의 형식을 만든 뒤,\n",
    "절편과 2차함수의 최소값을 구해 연결하고 연립방정식을 풀어 기울기를 구한다. \n",
    "\n",
    "이제, 가상의 데이터를 통해 선형회귀가 어떠한 방식으로 데이터를 설명하는지를 알아볼 것이다.\n",
    "보다 더 상세한 정보를 알고 싶다면,\n",
    "\"https://ko.wikipedia.org/wiki/선형_회귀\" 를 참고하여도 좋을 것이다. \n",
    "데이터는 sklearn 모듈을 사용하여 가상의 데이터를 생성할 것이다. \n",
    "\"\"\"\n",
    "print(\"Hello, Linear Regression!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression #가상의 회귀분석용 데이터 생성\n",
    "from sklearn.linear_model import LinearRegression # LinearRegression 모델 \n",
    "from sklearn.model_selection import train_test_split # Trainset, Testset 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make_regression? 를 사용하면, 함수에 대한 설명문을 제공한다.이를 참고하는 것도 좋을 것이다.\n",
    "make_regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input_feature:\n",
      " [[ 1.44722217  0.33225579 -0.04225817]\n",
      " [-0.23760795 -1.77620172 -2.09807064]\n",
      " [ 0.81012375 -2.80483886  0.66425824]\n",
      " [-0.24537947 -0.05699653  1.09439372]\n",
      " [-0.1173281  -1.08623389 -0.07243509]]\n",
      "Target_value: \n",
      "[  24.17804636 -252.95116321   -1.62023779  100.3268664   -38.02101536] \n"
     ]
    }
   ],
   "source": [
    "# 실습에 사용할 데이터는, make_regression에서 제공하는 기본 format을 사용하나, 약간의 수정을 했다.\n",
    "# concept을 익히는 것이 주 목적이기 때문에, feature수를 3개로 줄이고, random_state에 1994를 사용하여 고정했다.\n",
    "# 만약 feature수를 늘리거나, random_state의 숫자를 바꾸면 데이터가 변할 것이다. \n",
    "X, y = make_regression(\n",
    "    n_samples=100,\n",
    "    n_features=3,\n",
    "    n_informative=10,\n",
    "    n_targets=1,\n",
    "    bias=0.0,\n",
    "    effective_rank=None,\n",
    "    tail_strength=0.5,\n",
    "    noise=0.0,\n",
    "    shuffle=True,\n",
    "    coef=False,\n",
    "    random_state=1994,\n",
    ")\n",
    "# n_samples = 샘플의 숫자\n",
    "# n_features = 특징의 개수. (독립변수)\n",
    "# n_informative\n",
    "# n_targets\n",
    "# bias = y절편. 편향. 얼마만큼 치우쳐저 있는가?\n",
    "# effective_rank = \n",
    "# tail_strength = \n",
    "# noise = 퍼져있는 정도\n",
    "# shuffle = 데이터를 섞을 것인가?\n",
    "# coef = coefficient, 가중치\n",
    "# random_state = 무작위로 뽑지만, 그 추출치를 고정시킨다. 아무 난수나 입력가능.\n",
    "\n",
    "# feature수를 3개로 설정하고, X와 y값을 5개씩 출력\n",
    "print('Input_feature:\\n {}\\nTarget_value: \\n{} '.format(X[:5], y[:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(X), type(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 그래프를 그려서 산포도를 확인\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(X[:, 2], y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression 클래스 객체 생성 \n",
    "model = LinearRegression() # fit_intercept = 상수항 유무 결정 \n",
    "\n",
    "# fit 메서드로 모형 추정 (오그멘테이션은 자동으로 수행) \n",
    "model_lr = model.fit(X_train, y_train)\n",
    "# 내부적으로 R^2(결정계수)를 계산해준다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight:  [13.27551676 27.16263115 96.06467921]\n",
      "3 개\n",
      "bias:  7.105427357601002e-15\n"
     ]
    }
   ],
   "source": [
    "print('weight: ', model_lr.coef_) # feature의 개수만큼 나온다. \n",
    "print(len(model_lr.coef_), '개')\n",
    "print('bias: ', model_lr.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
